# 动手学习深度学习

有一件事情困扰我跟小伙伴们很久：每当MXNet发布新特性的时候，评论区免不了总有“做啥子新东西，赶紧去更新文档”类似的留言。我们曾一度都很费解，我们文档明明也很多啊，你看隔壁家，人家都没文档，大家照样也不是用的很嗨。直到后来有天Zack问了这样一个问题：假设回到你刚开始学机器学习的时候，你觉得现在你需要什么样的文档？

我是大二开始接触机器学习。当时候并没有太多很好资料，每天抱着晦涩的翻译版《The Elements of Statistical Learning》，读了大半年仍是懵懵懂懂。后来08年的时候出来了《Pattern Recognition And Machine Learning》，又啃了好几个月，被贝叶斯那一套绕得云里雾里。10年去港科大的时候James问我，你最熟悉的模型是哪个？使劲想了想，竟然答不出来。在港科大的两年读了很多论文，但反过来看，现在仍然记得可能就是那两个老老实实动手实现过写过论文的模型了。

虽然在我认识的人里，好些人能够在读一篇论文或者听一个报告后就能问出很好的问题，然后就似乎基本懂了。但我自己在这一点上会笨很多。读过的论文就像喝过的水，第二天就不记得了。所以一定需要静下心来，从头到尾实现一篇，跑上几个数据，挑些参数，才能放心的觉得我应该知道这个了。

![](img/why1.png)

在几年前机器学习重视理论分析的年代，不写代码不跑实验也能做出很好的工作。但在深度学习兴起的这几年，动手能力才是核心竞争力。就算我熟知卷积的三种写法，Relu的十个变种，理解BatchNorm为什么能加速收敛，对ImagenetNet历届冠军的错误率随手拈来，能滔滔不绝说上几小时神经网络几度沉浮的恩怨史。但调不出参数一切都是枉然。发论文被问你为啥跟state-of-the-art差老远，做产品被喷你这精度还不如我的便宜100倍的线性模型。

![](img/why2.png)

前些天Andrew宣布他的新深度学习课程，虽然没有花钱注册看下究竟，但从课程单上看是极好的。讲得非常全。Andrew讲东西一向特别清楚，所以这个课程必然是精品。

但回到最开始的那个问题，回到刚开始接触机器学习的时候，想要的是什么样的教材呢？Andrew的课自然是最好的选择之一，但仍有三个可以改进的地方：

1. 中文。即使已经用英文工作了将近十年，但中文的阅读和沟通仍然是方便很多。例如我现在更愿意去朋友圈里翻译的文章，而不是去看原文（好吧，太对不起英语老师了）。
2. 更多动手样例。虽然我也很喜欢听道理，但更喜欢“show me the codes”。高质量的代码，比文字更有用。
3. 能免费最好，不然至少可以微信支付吧。

在这两点上，我们有得天独厚的优势。一是我跟小伙伴在过去几年里都专注在打造深度学习框架，既给自己也帮别人实现和调试过大量算法。二是小伙伴们主要是中国人为主，所以我们更关注中文的生态圈。

所以我们一直在想，要不要开设一些系列课程，从深度学习入门到最新最前言的算法，从0开始通过交互式的代码来讲解每个算法和概念。我们讲专注提升动手能力，目的是大家通过这门课后，既能了解最近算法的细节，又能调得出参数做得了竞赛和产品。

为此我们做了这三件事情：

1. Eric带着一帮小伙伴做了MXNet的新前端Gluon，详细可以参见[他的blog](https://zhuanlan.zhihu.com/p/28648399)。这个前端带来跟Python更一致的便利的编程环境，不管是debug还是在交互上，都比TensorFlow之类通过计算图编程的框架更适合学习深度学习。
2. Zack带着另一帮小伙伴写了一系列的notebook来讲解各个模型。他从一个外行（他是专业音乐人）和老师（CMU计算机教授）的角度，从0开始实现各个算法。
3. 我们也组织将所有notebook翻译成中文，并建立中文社区来讨论和学习。

当然，毕竟我们不是全职做教学，时间上和经验上都不能跟专业人士媲美。但我们尽我们所能来精心挑选大纲，积极参与互动，而且不收取任何费用。我们将联合将门先讲4期，之后收集大家的反馈看看接下来哪种形式是最有效的。

具体的报名地址是，时间是北京时间周二周四中午一点（或者上午11点？这个点美东有点尴尬），
