# 简介
:label:`chap_introduction`

直到最近，我们每天与每天互动的几乎所有计算机程序都是由软件开发人员从第一原则编码的。假设我们想编写一个应用程序来管理电子商务平台。在闲逛白板上几个小时以思考问题之后，我们会想出一个可能看起来像这样的工作解决方案的广泛划线：(i) 用户通过网络浏览器或移动应用程序中运行的界面与应用程序进行交互；(ii) 我们的应用程序与商业级数据库引擎互动，以跟踪每个用户的状态并维护历史交易记录；以及 (iii) 在我们应用程序的核心，我们应用程序的 * 业务逻辑 *（你可能会说，*brain*）有条不紊地详细说明我们的适当行动程序应该考虑到所有可能的情况。

为了建立应用程序的大脑，我们必须逐步处理我们预期遇到的每一个可能的角落案例，制定适当的规则。每次买家单击将商品添加到购物车时，我们都会在购物车数据库表中添加一个条目，将该用户的 ID 与请求的产品 ID 关联起来。虽然很少有开发人员第一次完全正确地做到它（可能需要一些测试才能解决问题），但在大多数情况下，我们可以从第一个原则编写这样的程序并自信地启动它
*之前 * 见过真正的客户。
我们能够从最初的原则来设计自动化系统，这些原则通常是在新的情况下驱动正常的产品和系统，这是一项显著的认知成就。而且，当你能够设计出能够在 100 美元时间工作的解决方案时，你不应该使用机器学习。

幸运的是，对于不断增长的机器学习科学家社区来说，我们希望自动化的许多任务并不容易弯曲到人类的聪明才智。想象一下，用你认识的最聪明的头脑挤在白板上，但这次你正在解决以下问题之一：

* 编写一个程序，根据地理信息、卫星图像和过去天气的尾随窗口来预测明天的天气。
* 编写一个以自由格式文本表示的问题的程序，然后正确回答它。
* 编写一个程序，给出图像可以识别其中包含的所有人物，并在每个人周围绘制轮廓。
* 编写一个程序，向用户提供他们可能喜欢但在自然浏览过程中不可能遇到的产品。

在每种情况下，即使是精英程序员也无法从头开始编写解决方案。造成这种情况的原因可能不同。有时我们正在寻找的计划遵循随着时间而变化的模式，我们需要我们的计划进行调整。在其他情况下，关系（比如像素和抽象类别之间）可能太复杂，需要数千或数百万计算，这些计算超出了我们的意识，即使我们的眼睛能够毫不费力地管理任务。
*机器学习 * 是对功能强大的研究
可以从经验中学习的技巧。随着机器学习算法积累更多体验（通常是观察数据或与环境的交互），因此其性能会提高。与我们的确定性电子商务平台相比，无论积累了多少经验，该平台都按照相同的业务逻辑执行，直到开发人员自己学习并决定是时候更新软件为止。在本书中，我们将教你机器学习的基础知识，尤其关注 * 深度学习 *，这是一套强大的技术，推动计算机视觉、自然语言处理、医疗保健和基因组学等领域的创新。

## 一个激励性的例子

在开始写作之前，这本书的作者和大部分劳动力一样，必须变成咖啡因。我们跳进车里开始开车亚历克斯用 iPhone 呼叫 “嘿 Siri”，唤醒手机的语音识别系统。然后 Mu 命令 “前往蓝瓶咖啡店的路线”。电话很快显示了他命令的转录。它还认识到我们在询问路线，并启动了地图应用程序（应用程序）来满足我们的要求。地图应用程序启动后，识别了多条路线。在每条路线旁边，电话会显示预计的运输时间。虽然我们为了教学方便而编造这个故事，但它表明，在短短几秒钟内，我们与智能手机的日常互动就可以使用多种机器学习模型。

想象一下，只需编写一个程序来回应 “Alexa”、“好谷歌” 和 “嘿 Siri” 等 * 叫醒词 *。如 :numref:`fig_wake_word` 所示，尝试自己在房间里自己只用计算机和代码编辑器对其进行编码。你将如何从第一个原则编写这样的程序？想想一下... 问题很难。每秒钟，麦克风将收集大约 44000 个样本。每个样本都是对声波振幅的测量。什么规则可以从原始音频片段可靠地映射到关于片段是否包含唤醒词的自信预测 $\{\text{yes}, \text{no}\}$？如果你被卡住了，不要担心。我们也不知道如何从头开始编写这样的程序。这就是为什么我们使用机器学习。

![Identify a wake word.](../img/wake-word.svg)
:label:`fig_wake_word`

这是诀窍。通常，即使我们不知道如何明确地告诉计算机如何将输入映射到输出，但我们仍然能够自己执行认知壮举。换句话说，即使你不知道如何编程计算机来识别 “Alexa” 一词，你自己也能够识别它。有了这种能力，我们可以收集一个巨大的 * dataset*，其中包含音频和标签示例，但不包含唤醒词。在机器学习方法中，我们不尝试设计系统
*明确地 * 来识别醒来的话。
相反，我们定义了一个灵活的程序，其行为由多个 * 参数 * 决定。然后我们使用数据集来确定尽可能最佳的参数集，这些参数可以提高我们程序在某种程度的感兴趣任务绩效方面的绩效。

你可以把参数视为我们可以转动的旋钮，操纵程序的行为。修复参数，我们称该程序为 * 模型 *。我们只需通过操作参数即可生成的所有不同程序（输入-输出映射）集被称为 * 族 * 模型。而使用我们的数据集选择参数的元程序被称为 * 学习算法 *。

在我们继续使用学习算法之前，我们必须精确定义问题，确定输入和输出的确切性质，并选择合适的模型系列。在这种情况下，我们的模型接收音频片段作为 * 输入 *，模型在 $\{\text{yes}, \text{no}\}$ 中生成一个选择，作为 *output*。如果一切都按计划进行，模型对于片段是否包含唤醒词通常是正确的。

如果我们选择合适的型号系列，那么应该有一个旋钮设置，以便模型每次听到 “Alexa” 一词时都会触发 “是”。由于唤醒词的确切选择是任意的，所以我们可能需要一个足够丰富的模特家族，通过另一种旋钮设置，它只有在听到 “Apricot” 一词时才能触发 “是”。我们预计同一个模型家族应该适合 “Alexa” 认可和 “Apricot” 认可，因为直觉上它们似乎是类似的任务。但是，如果我们想要处理根本不同的输入或输出，比如说我们想要将图像映射到字幕，或者从英语句子到中文句子，我们可能需要完全不同的模型系列。

正如你可能猜到的那样，如果我们只是随机设置所有旋钮，我们的模型不太可能识别 “Alexa”、“Apricot” 或任何其他英语单词。在机器学习中，* learning* 是我们发现旋钮的正确设置以强制模型中所需行为的过程。换句话说，我们用数据训练 * 我们的模型。如 :numref:`fig_ml_loop` 所示，培训过程通常如下所示：

1. 从随机初始化的模型开始，该模型无法做任何有用。
1. 抓住一些数据（例如，音频片段和相应的 $\{\text{yes}, \text{no}\}$ 标签）。
1. 调整旋钮，使模型相对于这些示例来说会减少吸引力。
1. 重复步骤 2 和 3，直到模型很棒。

![A typical training process.](../img/ml-loop.svg)
:label:`fig_ml_loop`

总而言之，我们不是编写唤醒词识别器的代码，而是编写一个程序，如果我们用大型标记的数据集呈现它，它可以 * 学习 * 来识别唤醒单词。你可以想象这种决定程序行为的行为的行为，方法是将其与数据集一起呈现为 * 使用 data 编程 *。也就是说，我们可以通过向我们的机器学习系统提供许多猫狗示例来 “编程” 猫探测器。这样，如果是猫，探测器最终将学会发出一个非常大的正数，如果是狗，则会发出一个非常大的负数，如果不确定，则会发出接近零的东西，这几乎不会划伤机器学习能做到的表面。深度学习只是解决机器学习问题的许多常用方法中的一种，我们稍后将对此进行更详细的解释。

## 关键组件

在我们的 “唤醒词汇” 示例中，我们描述了一个由音频片段和二进制标签组成的数据集，并且我们对我们如何训练模型以近似从片段到分类的映射进行了手波浪感。这种问题称为 * 监督学习 *，我们试图根据已知输入预测指定的未知标签，假定一个由标签已知示例组成的数据集。这只是许多机器学习问题中的一个。稍后我们将深入研究不同的机器学习问题。首先，无论我们遇到什么样的机器学习问题，我们都希望更多地了解一些将跟随我们的核心组件：

1. 我们可以从中学习的 * 数据 *。
1. 如何转换数据的 * 模型 *。
1. 一个 * 目标函数 *，用于量化模型表现如何（或糟糕）。
1. 用于调整模型参数以优化目标功能的 * 算法 *。

### 数据

不言而喻，没有数据就无法进行数据科学。我们可能会丢失数百页，思考究究竟是什么数据，但是现在，我们将在实际方面出错，专注于需要关注的关键属性。一般来说，我们关心的是一系列示例。为了有效地处理数据，我们通常需要提供合适的数字表示。每个 * 例子 *（或 * 数据点 *、* 数据实例 *、* 样本 *）通常由一组名为 *Features *（或 * 协变量 *）的属性组成，模型必须从中进行预测。在上述受监督的学习问题中，要预测的是指定为 *label*（或 *target*）的特殊属性。

如果我们正在处理图像数据，每张照片都可能构成一个例子，每张照片都由与每个像素的亮度相对应的有序数值列表表示。$200\times 200$ 彩色照片将由 $200\times200\times3=120000$ 数值组成，对应于每个空间位置的红色、绿色和蓝色通道的亮度。在另一项传统任务中，鉴于年龄、生命体征和诊断等标准特征集，我们可能会尝试预测患者是否能够存活。

当每个例子的特征是相同数量的数值时，我们说数据由固定长度的矢量组成，我们将向量的常量长度描述为数据的 *dimensionality*。正如你可能想象的，固定长度可能是一个方便的酒店。如果我们想训练一个模型来识别显微镜图像中的癌症，固定长度的输入意味着我们只需要担心一件事。

但是，并非所有数据都能很容易地表示为
*固定长度 * 向量。
虽然我们可能期望显微镜图像来自标准设备，但我们不能期望从互联网开采的图像都会以相同的分辨率或形状显示出来。对于图片，我们可能会考虑将它们全部裁剪为标准尺寸，但这种策略只能让我们获得目前为止。我们可能会丢失裁剪部分的信息。此外，文本数据更顽固地抵制固定长度的表示。考虑亚马逊、IMDB 和 TripAdvisor 等电子商务网站上留下的客户评论。有些是简短的：“很臭！”。其他人漫游网页。与传统方法相比，深度学习的一个主要优势是现代模型可以处理 * 变长 * 数据的比较优势。

一般来说，我们拥有的数据越多，我们的工作就越容易。当我们有更多的数据时，我们可以训练更强大的模型，而减少对预先设想的假设的依赖。政权从（相对而言）小数据转变为大数据是现代深度学习成功的主要因素。为了推动重点，如果没有大型数据集，深度学习中许多最令人兴奋的模型就无法正常工作。其他一些人在小型数据系统中工作，但并不比传统方法更好。

最后，仅仅拥有大量数据并对其进行巧妙处理是不够的。我们需要 * 右 * 数据。如果数据充满错误，或者选择的要素无法预测感兴趣的目标数量，学习将失败。陈词滥调很好地掌握了情况：
*垃圾进来，垃圾出来 *。
此外，预测性能不佳并不是唯一的潜在后果。在机器学习的敏感应用中，例如预测性监管、简历筛选和用于贷款的风险模型，我们必须特别警惕垃圾数据的后果。在训练数据中未表示某些人群的数据集中会出现一种常见的故障模式。想象一下，在野外应用以前从未见过黑皮肤的皮肤癌识别系统。如果数据不仅不足以代表某些群体，而且反映了社会偏见，也可能会发生失败。例如，如果利用过去的招聘决策来训练用于筛选简历的预测模型，那么机器学习模型可能会无意中捕获并自动执行历史不公正现象。请注意，在没有数据科学家积极密谋甚至没有意识到的情况下，这一切都可能发生。

### 模型

大多数机器学习都涉及在某种意义上转换数据。我们可能想建立一个摄取照片并预测笑脸的系统。或者，我们可能想摄取一组传感器读数并预测读数的正常与异常程度。通过 *model*，我们表示用于摄取一种类型的数据并吐出可能不同类型的预测的计算机制。特别是，我们对可以从数据中估算的统计模型感兴趣。虽然简单的模型完全能够解决适当简单的问题，但我们在本书中关注的问题却延伸了传统方法的极限。深度学习与传统方法的区别主要是它关注的一组强大模型。这些模型包括从上到下链接在一起的数据的许多连续转换，因此名称为 * 深度学习 *。在我们讨论深度模型的途中，我们还将讨论一些更传统的方法。

### 目标函数

此前，我们介绍了机器学习，作为从经验中学习。在这里 * 学习 *，我们的意思是随着时间的推移在某项任务上的改善。但是谁应该说什么构成改进？你可能会想象我们可以提议更新我们的模型，有些人可能会对提议的更新是改善还是下降存在异议。

为了开发一个正式的学习机数学系统，我们需要对我们的模型有多好（或坏）进行正式的衡量。在机器学习和更普遍的优化中，我们称之为这些 * 目标函数 *。按照惯例，我们通常定义客观函数，以便越低越好。这只是一项约定。你可以选择任何越高越好的函数，然后将其变成一个质量相同但通过翻转标志来降低更好的新函数。因为越低越好，这些函数有时被称为
*损失函数 *。

当尝试预测数值时，最常见的损失函数是 * 平方误差 *，即预测和地面真相差值的平方。对于分类，最常见的目标是尽量减少错误率，即我们预测与基本真相不一致的例子的一部分。某些目标（例如，平方误差）很容易优化。其他（例如错误率）由于不可区分或其他复杂情况，难以直接优化。在这些情况下，通常优化 * 代理对象 *。

通常，损失函数是根据模型的参数定义的，并取决于数据集。我们通过最大限度地减少一组由为训练而收集的一些示例组成的损失，从而了解模型参数的最佳价值。但是，在训练数据上做得很好并不能保证我们在看不见的数据上做得很好。因此，我们通常希望将可用数据拆分成两个分区：* 训练数据集 *（或 * 训练集 *，用于拟合模型参数）和 *test 数据集 *（或用于评估的 *test set*），报告模型在两个分区上的表现。你可以认为训练表现就像学生在用于准备一些真正的期末考试的模拟考试中的分数一样。即使结果令人鼓舞，但这也不能保证期末考试的成功。换句话说，测试表现可能与训练表现有很大差异。当模型在训练集上表现良好但未能概括到看不见的数据时，我们说它是 * overfit *。在现实生活中，尽管练习考试表现良好，但这就像在真正的考试中取消一样。

### 优化算法

一旦我们获得了一些数据源和表示、模型以及明确定义的目标函数，我们需要一种能够搜索最佳参数以最大限度地减少损失函数的算法。深度学习的流行优化算法基于名为 * 梯度血统 * 的方法。简而言之，在每个步骤中，此方法都会检查每个参数的情况下，如果您只打扰了该参数少量，训练集损失会以何种方式移动。然后，它会沿着可能减少损失的方向更新参数。

## 机器学习问题的种类

我们激励性示例中的唤醒词问题只是机器学习可以解决的众多问题中的一个。为了进一步激励读者并在我们谈论整本书中的更多问题时为我们提供一些共同语言，在下面我们列出了机器学习问题的示例。我们将不断参考上述概念，例如数据、模型和训练技巧。

### 有监督的学习

监督学习解决了预测给定输入要素的标注的任务。每个功能-标签对都被称为一个示例。有时，当上下文清晰时，我们可能会使用术语 *example* 来表示输入的集合，即使相应的标签未知也是如此。我们的目标是生成一个将任何输入映射到标签预测的模型。

为了把这种描述作为一个具体的例子，如果我们在医疗保健领域工作，那么我们可能想预测患者是否会发作心脏病。这种观察，“心脏病发作” 或 “无心脏病发作”，将成为我们的标签。输入要素可能是心率、舒张压和收缩压等生命体征。

监督之所以起作用，是因为为了选择参数，我们（主管）为模型提供了一个由标记示例组成的数据集，其中每个示例都与地面真相标签匹配。就概率而言，我们通常对估计给定输入要素的标签的条件概率感兴趣。虽然监督学习只是机器学习中的几个范例之一，但监督学习占了行业中成功应用机器学习的大多数。部分原因是，在考虑到一组特定的可用数据的情况下，可以将许多重要任务清晰地描述为估计未知事件的可能性：

* 根据计算机断层扫描图像，预测癌症与不是癌症。
* 用英语给出一句话，预测法语的正确翻译。
* 根据本月的财务报告数据，预测下个月股票的价格。

即使使用简单的描述 “预测给定的输入要素的标签”，监督学习也可以采取很多形式，并且需要大量的建模决策，具体取决于（除其他考虑因素外）的类型、大小以及输入和输出的数量。例如，我们使用不同的模型来处理任意长度的序列以及处理固定长度的矢量表示。我们将在本书中深入探讨其中的许多问题。

非正式地说，学习过程如下所示。首先，获取已知特征的大量示例，然后从中选择一个随机子集，获取每个特征的基本真实标签。有时这些标签可能是已经收集的可用数据（例如，病人是否在下一年内死亡？）而其他时候，我们可能需要雇用人工注释者来标记数据（例如，将图片分配给类别）。这些输入和相应的标签共同构成了训练集。我们将训练数据集输入到受监督的学习算法中，该算法将数据集作为输入并输出另一个函数：学习模型。最后，我们可以将之前看不见的输入提供给学习模型，将其输出作为相应标签的预测。整个过程是在 :numref:`fig_supervised_learning` 中绘制的。

![Supervised learning.](../img/supervised-learning.svg)
:label:`fig_supervised_learning`

#### 回归

也许最简单的监督式学习任务可能是 * Regression*。例如，考虑从房屋销售数据库中收集的一组数据。我们可能会构造一张桌子，其中每一行对应于不同的房屋，每列对应于某些相关属性，例如房屋的平方英尺、卧室数量、浴室数量以及到镇中心的分钟数（步行）。在此数据集中，每个示例都将是一个特定的房屋，相应的要素矢量将是表中的一行。如果你住在纽约或旧金山，而你不是亚马逊、谷歌、微软或 Facebook 的首席执行官，那么你家的（平方小镜头、卧室数量、浴室数量、步行距离）特征矢量可能如下：$[600, 1, 1, 60]$。但是，如果你住在匹兹堡，它可能看起来更像 $[3000, 4, 3, 10]$。像这样的功能向量对于大多数经典的机器学习算法至关重要。

使问题成为回归的原因实际上是输出。假设你在市场上购买新房。考虑到上述一些功能，您可能需要估计房屋的公平市场价值。标签，即销售价格，是一个数值。当标签采用任意数值时，我们将其称为 * 回归 * 问题。我们的目标是生成一个预测与实际标签值接近的模型。

许多实际问题都是描述良好的回归问题。预测用户将分配给电影的评级可以被视为回归问题，如果你设计了一个很好的算法来在 2009 年实现这一壮举，你可能已经赢得了 [1-million-dollar Netflix prize](https://en.wikipedia.org/wiki/Netflix_Prize)。预测病人在医院的住宿时间也是一个倒退问题。一个很好的经验法则是有 * 多少钱？* 或 * 有多少？* 问题应该建议回归，例如：

* 这种手术需要多少小时？
* 在接下来的六个小时内，这个城镇会有多少降雨量？

即使你以前从未使用过机器学习，但你可能已经非正式地解决了回归问题。例如，想象一下，你已经修理了排水管，承包商花了 3 个小时去除污水管道上的垃圾。然后他给你发了一张 350 美元的账单。现在想象一下，你的朋友雇用了同一个承包商 2 个小时，他收到了 250 美元的账单。如果有人随后问你预期他们即将到来的枪支清除发票上有多少，你可能会做出一些合理的假设，例如更多的工作时间花费更多的美元。您可能还假设有一些基本费用，然后承包商按小时收费。如果这些假设成立，那么鉴于这两个数据示例，您已经可以确定承包商的定价结构：每小时 100 美元加 50 美元出现在你家里。如果你关注这么多，那么你已经理解了线性回归背后的高级思想。

在这种情况下，我们可以生成与承包商价格完全匹配的参数。有时这是不可能的，例如，如果某些差异是由于除了两个功能之外的几个因素造成的。在这些情况下，我们将尝试学习将预测与观测值之间的距离最小化的模型。在我们的大多数章节中，我们将专注于最大限度地减少平方错误损失函数。正如我们稍后将看到的那样，这种损失与我们的数据被高斯噪音损坏的假设相对应。

#### 分类

虽然回归模型非常适合解决 * 多少？* 问题，很多问题不能舒适地弯曲到这个模板。例如，银行希望将支票扫描添加到其移动应用程序。这需要客户用智能手机的相机拍摄支票的照片，应用程序需要能够自动理解图像中看到的文字。具体来说，它还需要理解手写文本才能更加强大，例如将手写字符映射到已知字符之一。这种 * 哪一个？* 问题被称为 * 分类 *。尽管许多技术将继续使用，但它的处理方法与用于回归的算法不同。

在 * 分类 * 中，我们希望模型能够查看特征，例如，图像中的像素值，然后预测在某些离散选项集中，哪个 * 类别 *（正式称为 *class *）是一个例子。对于手写数字，我们可能有十个类，对应于数字 0 到 9。最简单的分类形式是只有两个类，这是我们称之为 * 二进制分类 * 的问题。例如，我们的数据集可能包含动物图像，我们的标签可能是 $\mathrm{\{cat, dog\}}$ 类。在回归中，我们寻求回归器来输出数值，在分类中，我们寻找一个分类器，其输出是预测的类赋值。

由于随着书的技术性越来越高，我们将进入这本书的技术性，因此很难优化只能输出硬分类分配的模型，例如 “猫” 或 “狗”。在这些情况下，用概率语言表达我们的模型通常要容易得多。鉴于示例的特征，我们的模型为每个可能的类分配一个概率。回到我们的动物分类示例，其中类别为 $\mathrm{\{cat, dog\}}$，分类器可能会看到一张图像，然后将图像是猫的概率输出为 0.9。我们可以通过说分类器是 90\ ％ 来解释这个数字，确保图像描绘了一只猫。预测阶级的概率大小表达了一种不确定性的概念。这不是唯一的不确定性概念，我们将在更高级的章节中讨论其他概念。

当我们有两个以上可能的类时，我们将问题称为 * 多类分类 *。常见的例子包括手写字符识别 $\mathrm{\{0, 1, 2, ... 9, a, b, c, ...\}}$。虽然我们通过尝试最大限度地减少平方误差损失函数来攻击回归问题，但分类问题的常见损失函数被称为 *交叉entropy*，可以通过在后续章节中介绍信息理论来揭开其名称的神秘性。

请注意，最有可能的课程不一定是你将用来做决定的课程。假设你在后院里找到了一个美丽的蘑菇，如 :numref:`fig_death_cap` 所示。

![Death cap---do not eat!](../img/death-cap.jpg)
:width:`200px`
:label:`fig_death_cap`

现在，假设你构建了一个分类器并训练它来根据照片预测蘑菇是否有毒。假设我们的毒物检测分类器输出 :numref:`fig_death_cap` 包含死亡上限的概率是 0.2。换句话说，分类器是 80\ ％ 确定我们的蘑菇不是死亡上限。尽管如此，你必须是个傻瓜才能吃掉它。这是因为美味晚餐的某种好处不值得 20\ ％ 的死亡风险。换句话说，到目前为止，不确定风险的影响超过了收益。因此，我们需要计算作为亏损函数所承受的预期风险，即我们需要将结果的概率与与其相关的利益（或伤害）乘以。在这种情况下，食用蘑菇造成的损失可能是 $0.2 \times \infty + 0.8 \times 0 = \infty$，而丢弃的损失为 $0.2 \times 0 + 0.8 \times 1 = 0.8$。我们的谨慎是合理的：正如任何真菌学家都会告诉我们的那样，:numref:`fig_death_cap` 中的蘑菇实际上是死亡帽。

分类可能比仅仅是二进制、多类甚至多标签分类复杂得多。例如，有一些分类变体可用于解决层次结构。层次结构假设许多类之间存在一些关系。因此，并非所有错误都是平等的，如果我们必须错误，我们宁愿将错误分类到相关类别而不是遥远的班级。通常，这被称为 * 层次分类 *。早期的一个例子是 [Linnaeus](https://en.wikipedia.org/wiki/Carl_Linnaeus) 的原因，他将动物组织在层次结构中。

在动物分类的情况下，将贵宾犬（狗品种）误认为雪纳瑞（另一种狗品种）可能不是那么糟糕，但是如果它混淆恐龙的贵宾犬，我们的模型将付出巨大的惩罚。哪个层次结构相关可能取决于您计划如何使用模型。例如，摇铃蛇和吊袜带蛇可能在系统发育树上靠近，但是错误用摇铃器换吊袜带可能是致命的。

#### 标记

一些分类问题完全适合二进制或多类分类设置。例如，我们可以训练一个普通的二进制分类器来区分猫和狗。鉴于计算机视觉的当前状态，我们可以使用现成的工具轻松完成此操作。尽管如此，无论我们的模型有多准确，当分类器遇到了 * 不来梅音乐家 * 的图像时，我们可能会发现自己陷入困境，这是一个流行的德国童话故事，在 :numref:`fig_stackedanimals` 中有四种动物。

![A donkey, a dog, a cat, and a rooster.](../img/stackedanimals.png)
:width:`300px`
:label:`fig_stackedanimals`

正如你所看到的，:numref:`fig_stackedanimals` 中有一只猫，还有一只公鸡、一只狗和一只驴，背景里有一些树木。根据我们最终想对模型做什么，将其视为二进制分类问题可能没有太大意义。相反，我们可能想让模特选择说图片描绘的是猫、狗、驴
*和 * 一只公鸡。

学习预测不相互排斥的课程的问题称为 * 多标签分类 *。自动标记问题通常最好地描述为多标签分类问题。想想人们可能会应用于技术博客上的帖子的标签，例如 “机器学习”、“技术”、“小工具”、“编程语言”、“Linux”、“云计算” 和 “AWS”。一篇典型的文章可能会应用 5-10 个标签，因为这些概念是相关的。关于 “云计算” 的帖子可能会提及 “AWS”，关于 “机器学习” 的帖子也可能涉及 “编程语言”。

在处理生物医学文献时，我们也必须处理这种问题，正确标记文章很重要，因为它允许研究人员对文献进行详尽的审查。在国家医学图书馆，许多专业注释者都会阅读在 PubMed 中编制索引的每篇文章，将其与 MeSh 的相关术语相关联，这是一个约 28000 个标签集合。这是一个耗时的过程，注释者通常在存档和标记之间有一年的滞后。机器学习可以在这里用来提供临时标签，直到每篇文章都能进行适当的手动审查。事实上，几年来，BioASQ 组织有 [hosted competitions](http://bioasq.org/) 来做到这一点。

#### 搜索

有时我们不只想将每个示例分配给存储桶或实际价值。在信息检索领域，我们想对一组项目进行排名。以网络搜索为例。目标不是确定某个特定页面是否与查询相关，而是要确定哪一个搜索结果与特定用户最相关。我们真的很关心相关搜索结果的排序，我们的学习算法需要从较大的搜索结果中生成有序的元素子集。换句话说，如果我们被要求从字母表中生成前 5 个字母，则返回 “A B C D E” 和 “C A B E D” 之间有区别。即使结果集相同，集中的顺序也很重要。

解决这个问题的一个可能的办法是首先为该集合中的每个元素分配一个相应的相关性分数，然后检索最高评分的元素。[PageRank](https://en.wikipedia.org/wiki/PageRank)，谷歌搜索引擎背后的原始秘密工具是这样一个评分系统的早期例子，但它确实很奇怪不取决于实际的查询。在这里，他们依靠简单的相关性过滤器来识别相关项目集，然后在 PageRank 对包含查询术语的结果进行排序。如今，搜索引擎使用机器学习和行为模型来获取与查询相关的相关性分数。有整个学术会议专门讨论这个主题。

#### 推荐人系统
:label:`subsec_recommender_systems`

推荐系统是另一个与搜索和排名相关的问题设置。就目标是向用户显示一组相关项目而言，问题也是相似的。主要区别在于
*个性化 *
在推荐系统中向特定用户提供。例如，对于电影推荐，科幻小说粉丝的结果页面和 Peter Solts 喜剧鉴赏家的结果页面可能会有很大差异。其他推荐设置中也会出现类似的问题，例如零售产品、音乐和新闻推荐。

在某些情况下，买家会提供明确的反馈，告诉他们对特定商品的喜爱程度（例如，亚马逊、IMDB 和 GoodReads 上的商品评级和评论）。在其他一些情况下，他们会提供隐性反馈，例如跳过播放列表上的标题，这可能表示不满，但可能只表明歌曲在上下文中不适当。在最简单的配方中，这些系统经过培训以估算某些分数，例如给定用户和物品的估计评级或购买概率。

考虑到这样的模型，对于任何给定的用户，我们都可以检索得分数最高的对象集，然后可以向用户推荐这些对象。生产系统要先进得多，在计算此类分数时将详细的用户活动和项目特征考虑在内。:numref:`fig_deeplearning_amazon` 是亚马逊推荐的深度学习书籍示例，该书基于调整用于捕获个人偏好的个性化算法。

![Deep learning books recommended by Amazon.](../img/deeplearning-amazon.jpg)
:label:`fig_deeplearning_amazon`

尽管建立在预测模型之上的推荐系统具有巨大的经济价值，但仍然存在一些严重的概念缺陷。首先，我们只观察 * 被审查的反馈 *：用户优先对他们感觉强烈的电影进行评级。例如，在五分尺度上，您可能会注意到物品获得了许多五星和一星评级，但三星评级显然很少。此外，当前的购买习惯通常是当前推荐算法的结果，但学习算法并不总是考虑到这一细节。因此，有可能形成反馈循环，推荐系统优先推荐物品，然后将其视为更好（由于购买量增加），反馈循环则更频繁地推荐。许多关于如何处理审查、激励和反馈循环的问题都是重要的公开研究问题。

#### 序列学习

到目前为止，我们已经研究了我们有一些固定数量的输入并产生固定数量的输出的问题。例如，我们考虑了从一组固定的功能来预测房价：平方英尺、卧室数量、浴室数量、前往市中心的步行时间。我们还讨论了从图像（固定维度）到属于固定数量类中每个类别的预测概率的映射，或者获取用户 ID 和产品 ID，然后预测星级。在这些情况下，一旦我们将固定长度输入馈入模型以生成输出，模型会立即忘记刚才看到的内容。

如果我们的输入确实都具有相同的维度，如果连续的输入真的彼此无关，这可能没问题。但是我们将如何处理视频片段？在这种情况下，每个片段可能包含不同数量的帧。如果我们考虑到之前或后续的帧，我们对每帧中发生的情况的猜测可能会更加强大。语言也是如此。一个流行的深度学习问题是机器翻译：用某种源语言摄取句子并预测其他语言翻译的任务。

这些问题也出现在医学中。我们可能需要一个模型来监控重症监护病房的患者，如果他们在未来 24 小时内的死亡风险超过某个阈值，就会发出警报。我们绝对不希望这个模型每小时丢掉它所知道的关于患者病史的一切，而只是根据最新的测量进行预测。

这些问题是机器学习中最令人兴奋的应用之一，它们是 * 序列学习 * 的实例。它们需要一个模型来摄取输入序列或发出输出序列（或两者）。具体来说，
*顺序到序列的学习 * 考虑问题
其中输入和输出都是可变长度的序列，例如机器翻译和口头演讲中的文本的转录。尽管不可能考虑所有类型的序列变换，但以下特殊情况值得一提。

** 标记和解析 **。这涉及使用属性对文本序列进行注释。
换句话说，投入和产出的数量基本相同。例如，我们可能想知道动词和主题在哪里。或者，我们可能想知道哪些词是命名实体。一般来说，目标是根据结构和语法假设对文本进行分解和注释，以获得一些注释。这听起来比实际上复杂得多。下面是一个非常简单的示例，使用标签来标注句子，指示哪些单词指的是命名实体（标记为 “EnT”）。

```text
Tom has dinner in Washington with Sally
Ent  -    -    -     Ent      -    Ent
```

** 自动语音识别 **。使用语音识别，输入序列
是扬声器的录音（如 :numref:`fig_speech` 所示），输出是发言者所说的文本记录。面临的挑战在于，音频帧（通常以 8kHz 或 16kHz 的速度采样）比文本多得多，也就是说，音频和文本之间没有 1:1 对应关系，因为数千个样本可能对应于单个口语。这些是对输出比输入短得多的学习问题进行排序的顺序。

![`-D-e-e-p- L-ea-r-ni-ng-` in an audio recording.](../img/speech.png)
:width:`700px`
:label:`fig_speech`

** 文字转语音 **。这是自动语音识别的反面。
换句话说，输入是文本，输出是音频文件。在这种情况下，输出比输入长得多。虽然人类很容易识别不好的音频文件，但这对计算机来说并不是那么微不足道。

** 机器翻译 **。与语音识别的情况不同，其中相应
输入和输出以相同的顺序（对齐后）进行，在机器翻译中，顺序倒置可能至关重要。换句话说，虽然我们仍在将一个序列转换为另一个序列，但是输入和输出的数量和相应数据示例的顺序都不会被假定是相同的。考虑以下说明德国人将动词放在句尾的奇特倾向的例子。

```text
German:           Haben Sie sich schon dieses grossartige Lehrwerk angeschaut?
English:          Did you already check out this excellent tutorial?
Wrong alignment:  Did you yourself already this excellent tutorial looked-at?
```

其他学习任务中会弹出许多相关问题。例如，确定用户阅读网页的顺序是二维布局分析问题。对话问题表现出各种其他复杂情况，决定接下来要说什么需要考虑到现实世界的知识和长时间对话的先前状态。这些都是积极的研究领域。

### 无人监督的学习

到目前为止，所有示例都与监督学习有关，即我们向模型提供一个包含要素和相应标签值的巨型数据集的情况。你可以认为这位受监督的学习者有一份非常专业的工作和一个非常平庸的老板。老板站在你的肩膀上，准确地告诉你在每种情况下该怎么做，直到你学会将情况映射到行动之前。为这样的老板工作听起来很糟糕。另一方面，这个老板很容易取悦。你只需尽快识别模式并模仿他们的行为。

以完全相反的方式，为一个不知道他们想要你做什么的老板工作可能会令人沮丧。但是，如果你打算成为数据科学家，你最好习惯它。老板可能只是交给你一个巨大的数据储存，然后告诉你用它做一些数据科学！* 这听起来很模糊，因为它确实如此。我们将这类问题称为 * 无监督学习 *，我们可以提出的问题的类型和数量仅受到我们的创造力的限制。我们将在后面的章节中讨论无监督的学习技巧。为了激发你现在的胃口，我们描述了你可能会问的以下几个问题。

* 我们能找到少量原型
准确地总结了数据？给定一组照片，我们能否将它们分成风景照片、狗、婴儿、猫和山峰的照片？同样，鉴于用户的浏览活动集合，我们能否将它们分组为具有类似行为的用户？这个问题通常被称为 * 集群 *。
* 我们能找到少量的参数
准确地捕获数据的相关属性？球的速度、直径和质量都很好地描述了球的轨迹。裁缝师已经开发了少量参数，这些参数相当准确地描述人体形状，以适合衣服。这些问题称为 * 子空间估计 *。如果依赖性是线性的，则称为 * 主成分分析 *。
* 是否有（任意结构化的）对象的表示
在欧氏空间里，这样符号性质可以很好地匹配？这可以用来描述实体及其关系，例如 “罗马” $-$ “意大利” $+$ “法国” $=$ “巴黎”。
* 有没有关于根本原因的描述
我们观察到的大部分数据？例如，如果我们有关于房价、污染、犯罪、地点、教育和薪水的人口统计数据，我们能不能仅根据实证数据发现它们之间的关系吗？与 * 因果关系 * 和
*概率图形模型 * 解决了这个问题。
* 无监督学习的另一个重要而令人兴奋的近期发展
是 * 生成对抗网络的出现 *。这为我们提供了一种程序性的方法来合成数据，甚至是像图像和音频这样的复杂结构化基本的统计机制是检查真实数据和虚假数据是否相同的测试。

### 与环境互动

到目前为止，我们还没有讨论数据实际来自何处，或者当机器学习模型生成输出时实际会发生什么。这是因为有监督的学习和无监督的学习不能以非常复杂的方式解决这些问题。无论哪种情况，我们都会提前获取大量数据，然后将模式识别机设置为运行状态，而无需再次与环境互动。由于所有学习都是在算法与环境断开之后进行的，所以这有时称为 * 离线学习 *。对于监督学习，考虑从环境中收集数据的过程看起来像 :numref:`fig_data_collection`。

![Collecting data for supervised learning from an environment.](../img/data-collection.svg)
:label:`fig_data_collection`

这种离线学习的简单性有其魅力。好处是，我们可以孤立地担心模式识别，而不会分散对这些其他问题的注意力。但缺点是，问题的提法非常有限。如果你更雄心勃勃，或者你长大后阅读 Asimov 的机器人系列，那么你可能会想象人为的智能机器人不仅能够做出预测，而且能够在世界上采取行动。我们想考虑智能 * 代理 *，而不仅仅是预测模型。这意味着我们需要考虑选择 * 行动 *，而不仅仅是做出预测。此外，与预测不同，行动实际上会影响环境。如果我们想培训智能代理人，我们必须考虑其行为可能对代理人未来的观察产生何种影响。

考虑到与环境的交互会带来一整套新的建模问题。以下只是几个例子。

* 环境记得我们之前做过什么吗？
* 环境是否希望帮助我们，例如用户在语音识别器中读取文本？
* 环境是否想要击败我们，即垃圾邮件过滤（针对垃圾邮件发送者）或玩游戏（与对手）之类的对抗设置？
* 环境不在乎吗？
* 环境有不断变化的动态吗？例如，未来的数据是总是与过去相似，还是随着时间的推移而变化模式是自然的还是为了响应我们的自动化工具？

最后一个问题提出了培训和测试数据不同的情况下 * 分布 Shift* 的问题。这是我们大多数人在参加讲师撰写的考试时遇到的一个问题，而家庭作业是由他的助教组成的。接下来，我们将简要介绍强化学习，这是一种明确考虑与环境互动的环境。

### 强化学习

如果你有兴趣使用机器学习来开发一个与环境交互并采取行动的代理，那么你可能会最终专注于 * 强化学习 *。这可能包括机器人、对话系统，甚至是开发视频游戏人工智能（AI）的应用。
*深度强化学习 *，适用
深度学习以加强学习问题，已经越来越受欢迎。仅使用视觉输入在 Atari 游戏中击败人类的突破性深度 Q 网络，以及在棋盘游戏 Go 上取消世界冠军的 Alphago 程序是两个突出的例子。

强化学习对问题进行了一个非常笼统的陈述，在这种情况下，座席在一系列时间步骤中与环境进行交互。在每个时间步骤中，工程师都会从环境中收到一些 * 观察 *，并且必须选择一个 * 操作 *，然后通过某种机制（有时称为执行器）传送回环境。最后，代理人从环境中获得奖励。:numref:`fig_rl-environment` 中说明了这一过程。然后，座席会收到后续观察，然后选择后续操作，依此类推。强化学习代理的行为受政策的约束。简而言之，* 政策 * 只是将环境观测映射到行动的函数。加强学习的目标是制定良好的政策。

![The interaction between reinforcement learning and an environment.](../img/rl-environment.svg)
:label:`fig_rl-environment`

强化学习框架的普遍性怎么强调也不过分。例如，我们可以把任何受监督的学习问题作为强化学习问题。假设我们有分类问题。我们可以创建一个强化学习代理，每个课程对应一个操作。然后，我们可以创造一个环境，给予的奖励与原始监督学习问题造成的损失函数完全相同。

话虽如此，强化学习还可以解决监督学习无法解决的许多问题。例如，在监督式学习中，我们始终希望训练输入与正确的标签相关联。但是，在强化学习中，我们并不认为对于每次观察，环境都会告诉我们最佳行动。一般来说，我们只能得到一些奖励。此外，环境甚至可能无法告诉我们哪些行动导致了奖励。

例如，考虑国际象棋游戏。唯一真正的奖励信号发生在游戏结束时，当我们赢了，我们可能会分配 1 的奖励，或者当我们输掉时，我们可以分配-1 的奖励。因此，强化学习者必须处理 * 信用分配 * 问题：确定结果需要信用哪些行动或归咎于哪些行动。对于 10 月 11 日获得晋升的员工来说，情况也是如此。这种促销可能反映了去年大量精心挑选的行动。未来获得更多促销活动需要弄清楚推广过程中的哪些行动。

强化学习者可能还必须处理局部可观察性的问题。也就是说，目前的观察可能不会告诉你关于你当前状态的一切。假设一个清洁机器人发现自己被困在房子里许多相同的壁橱中的一个。推断机器人的确切位置（以及状态）可能需要在进入衣柜之前考虑其先前的观察结果。

最后，在任何特定时刻，强化学习者都可能知道一项好政策，但可能还有许多其他更好的政策是代理人从未尝试过的。强化学习者必须不断选择是利用目前已知的最佳策略作为政策，还是 * 探索 * 战略空间，可能放弃一些短期奖励来换取知识。

一般的强化学习问题是一个非常普遍的环境。行动会影响后续的观察。奖励仅与所选操作相对应。环境可能会被完全或部分观察。立即考虑所有这些复杂性可能会要求研究人员太多。此外，并非每一个实际问题都表现出这些复杂性。因此，研究人员研究了一些强化学习问题的特殊案例。

当环境被充分观察时，我们将强化学习问题称为 * 马尔可夫决策过程 *。当状态不依赖于以前的行动时，我们将问题称为 * 上下文强盗问题 *。当没有州时，只有一组最初未知奖励的可用操作，这个问题就是经典的 * 多武强盗问题 *。

## 根

我们刚刚回顾了机器学习可以解决的一小部分问题。对于各种机器学习问题，深度学习为解决这些问题提供了强大的工具。尽管许多深度学习方法都是最近的发明，但使用数据和神经网络（许多深度学习模型的名称）进行编程的核心思想已经研究了几个世纪。事实上，人类一直渴望长期分析数据和预测未来结果，许多自然科学的根源在于这一点。例如，伯努利分布以 [雅各布·伯努利 (1655—1705 年)](https://en.wikipedia.org/wiki/Jacob_Bernoulli) 命名，而高斯分布是由 [Carl Friedrich Gauss (1777—1855)](https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss) 发现的。例如，他发明了最小平方算法，该算法今天仍被用于解决从保险计算到医疗诊断的无数问题。这些工具在自然科学领域产生了一种实验性方法，例如，欧姆关于电阻器中电流和电压的定律由线性模型完美描述。

即使在中世纪，数学家对估计也有敏锐的直觉。例如，[雅各布·柯贝尔 (1460—1533)](https://www.maa.org/press/periodicals/convergence/mathematical-treasures-jacob-kobels-geometry) 的几何书展示了平均 16 英尺的平均长度，以获得平均脚长。

![Estimating the length of a foot.](../img/koebel.jpg)
:width:`500px`
:label:`fig_koebel`

:numref:`fig_koebel` 说明了这个估算器的工作原理。这 16 名成年男子在离开教堂时被要求连续排队。然后，他们的总长度除以 16，以获得现在相当于 1 英尺的估计数。后来，这种 “算法” 被改进以处理英尺错误 —— 两个分别脚最短和最长英尺的男性被送走，平均数仅超过剩余人数。这是修整平均值估计的最早示例之一。

统计数据确实随着数据的收集和可用性而起飞。它的巨人之一，[罗纳德·费希尔（1890—1962 年）]（https://en.wikipedia.org/wiki/Ronald_Fisher），为其理论及其在遗传学中的应用做出了重大贡献。他的许多算法（例如线性判别分析）和公式（例如 Fisher 信息矩阵）如今仍在频繁使用。事实上，即使是费雪尔在 1936 年发布的 Iris 数据集，有时仍然用来说明机器学习算法。他也是优生学的支持者，这应该提醒我们，数据科学在道德上可疑的使用与其在工业和自然科学中的生产性应用一样长且持久。

机器学习的第二个影响来自 [Claude Shannon (1916—2001)] 的信息理论 (https://en.wikipedia.org/wiki/Claude_Shannon) 和通过 [艾伦·图灵 (1912—1954)](https://en.wikipedia.org/wiki/Alan_Turing) 进行的计算理论。图灵提出了 “机器能想到吗？”在他的著名论文 * 计算机械与智能 * :cite:`Turing.1950` 中。在他描述的图灵测试中，如果人类评估员难以根据文本交互来区分机器和人的回复，那么机器可以被视为 * 智能型 *。

另一种影响可以在神经科学和心理学中发现。毕竟，人类显然表现出聪明的行为。因此，询问是否可以解释这种能力并可能进行逆向工程，这是完全合理的。以这种方式启发的最古老的算法之一是由 [唐纳德·赫伯 (1904—1985)](https://en.wikipedia.org/wiki/Donald_O._Hebb) 制定的。在他的开创性著作 * 行为组织 * :cite:`Hebb.Hebb.1949` 中，他假设神经元通过积极的强化学习。这被称为 Hebbian 学习规则。它是 Rosenblatt 的感知器学习算法的原型，它奠定了许多支持当今深度学习的随机梯度下降算法的基础：强化理想的行为并减少不良行为，以获得神经网络中参数的良好设置。

生物灵感是为了 * 神经网络 * 它们的名字。一个多世纪以来（可以追溯到 1873 年亚历山大·贝恩和 1890 年詹姆斯·谢里灵顿的模型），研究人员一直在尝试组装类似于互动神经元网络的计算电路。随着时间的推移，对生物学的解释已经变得不那么纯粹，但名字被卡住了。在核心上，有几个关键原则可以在当今大多数网络中找到：

* 线性和非线性处理单元的交替，通常称为 * 层 *。
* 使用链规则（也称为 * 反向传播 *）来同时调整整个网络中的参数。

在初步迅速进展之后，神经网络的研究从 1995 年左右到 2005 年一直陷入困境。这主要是由于两个原因。首先，培训网络在计算上非常昂贵。尽管在上个世纪末随机存取内存充足，但计算能力却很稀缺。其次，数据集相对较小。事实上，Fisher 1932 年的虹膜数据集是测试算法功效的流行工具。包含 60000 个手写数字的 MNIST 数据集被认为是巨大的。

鉴于数据和计算匮乏，内核方法、决策树和图形模型等强大的统计工具在经验上被证明是优越的。与神经网络不同，它们不需要数周的时间进行训练，并提供了可预测的结果以强大的理论保

## 深度学习之路

由于万维网、为数亿用户提供服务的公司的出现、廉价、高质量传感器的传播、廉价的数据存储（Kryder 定律）和廉价的计算（摩尔法），尤其是在GPU 的形式，最初是为计算机游戏而设计的。突然之间，似乎计算上不可行的算法和模型变得相关（反之亦然）。:numref:`tab_intro_decade` 中最好地说明了这一点。

: 数据集与计算机内存和计算能力

|Decade|Dataset|Memory|Floating point calculations per second|
|:--|:-|:-|:-|
|1970|100 (Iris)|1 KB|100 KF (Intel 8080)|
|1980|1 K (House prices in Boston)|100 KB|1 MF (Intel 80186)|
|1990|10 K (optical character recognition)|10 MB|10 MF (Intel 80486)|
|2000|10 M (web pages)|100 MB|1 GF (Intel Core)|
|2010|10 G (advertising)|1 GB|1 TF (Nvidia C2050)|
|2020|1 T (social network)|100 GB|1 PF (Nvidia DGX-2)|
:label:`tab_intro_decade`

显然，随机存取内存没有跟上数据的增长。与此同时，计算能力的增长超过了可用数据的增长。这意味着，由于计算预算的增加，统计模型需要提高内存效率（通常通过添加非线性来实现），同时能够将更多时间花在优化这些参数上。因此，机器学习和统计的最佳点从（广义）线性模型和内核方法转向深度神经网络。这也是为什么许多深度学习的主要内容，例如多层感知器 :cite:`McCulloch.Pitts.1943`、卷积神经网络 :cite:`LeCun.Bottou.Bengio.ea.1998`、长短期内存 :cite:`Hochreiter.Schmidhuber.1997` 和 Q-Learning :cite:`Watkins.Dayan.1992`，在过去十年里基本上 “重新发现” 了深度学习的原因之一相当长的时间。

最近在统计模型、应用和算法方面的进展有时被比作寒武纪爆炸：物种进化迅速进展的时刻。事实上，最先进的不仅仅是用于数十年历史算法的可用资源的结果。请注意，下面的列表几乎没有触及过去十年来帮助研究人员取得巨大进展的想法的表面。

* 新的容量控制方法，例如 * 降落 * :cite:`Srivastava.Hinton.Krizhevsky.ea.2014`，有助于减轻过度装配的危险。这是通过在整个神经网络中应用噪声注入 :cite:`Bishop.1995` 来实现的，为训练目的，用随机变量替换权重。
* 注意机制解决了困扰统计数据超过一个世纪的第二个问题：如何在不增加可学习参数的情况下增加系统的内存和复杂性。研究人员通过使用只能被视为可学习的指针结构 :cite:`Bahdanau.Cho.Bengio.2014` 找到了一个优雅的解决方案。不必记住整个文本序列，例如对于固定维表示的机器翻译，而只需要存储一个指向翻译过程中间状态的指针。这大大提高了长序列的准确度，因为模型不再需要在开始生成新序列之前记住整个序列。
* 多阶段设计（例如，通过内存网络 :cite:`Sukhbaatar.Weston.Fergus.ea.2015` 和神经程序员-解释器 :cite:`Reed.De-Freitas.2015`）允许统计建模人员描述迭代推理方法。这些工具允许重复修改深度神经网络的内部状态，从而在推理链中执行后续步骤，类似于处理器为计算修改内存的方式。
* 另一个关键发展是生成式对抗网络 :cite:`Goodfellow.Pouget-Abadie.Mirza.ea.2014` 的发明。传统上，密度估计和生成模型的统计方法侧重于寻找适当的概率分布和（通常是近似的）算法来从中取样。因此，由于统计模型缺乏固有的灵活性，这些算法在很大程度上受到限制。生成对抗网络的关键创新是用具有可区分参数的任意算法取代采样器。然后对这些数据进行调整，以便鉴别器（实际上是双样本测试）无法区分虚假数据和真实数据。通过使用任意算法生成数据的能力，它为各种技术开辟了密度估计。斑马 :cite:`Zhu.Park.Isola.ea.2017` 和假名人面孔 :cite:`Karras.Aila.Laine.ea.2017` 的例子都证明了这一进展。即使是业余涂鸦师也可以根据描述场景布局 :cite:`Park.Liu.Wang.ea.2019` 的草图生成照片逼真的图像。
* 在许多情况下，单个 GPU 不足以处理可用于培训的大量数据。在过去的十年中，构建并行和分布式训练算法的能力有了显著提高。设计可扩展算法的关键挑战之一是，深度学习优化的主力（随机梯度下降）依赖于相对较小的小批量数据进行处理。同时，小批量限制了 GPU 的效率。因此，对 1024 个 GPU 进行培训，小批量尺寸为（比如每批 32 张图像）相当于约 32000 张图像的合计微型批量。最近的研究，首先是 Li :cite:`Li.2017`，随后是 :cite:`You.Gitman.Ginsburg.2017` 和 :cite:`Jia.Song.He.ea.2018`，将 iMagenet 数据集上 Resnet-50 模型的训练时间缩短到 7 分钟以内。相比之下，最初的培训时间是按天顺序衡量的。
* 并行化计算的能力也对强化学习的进展作出了相当重要的贡献，至少在模拟是一种选择时。这使计算机在 Go、Atari 游戏、星际争霸和物理模拟（例如使用 MujoCo）中实现超人性能方面取得了重大进展。例如，请参阅 :cite:`Silver.Huang.Maddison.ea.2016` 以了解如何在 Alphago 中实现此目标的说明。简而言之，如果有大量（状态、行动、奖励）三倍可用，即只要有可能尝试许多东西来了解彼此之间的关系，那么强化学习效果最好。模拟提供了这样的途径。
* 深度学习框架在传播思想方面发挥了关键作用。允许简单建模的第一代框架包括 [Caffe](https://github.com/BVLC/caffe)、[Torch](https://github.com/torch) 和 [Theano](https://github.com/Theano/Theano)。使用这些工具撰写了许多开创性的论文。到目前为止，它们已被 [TensorFlow](https://github.com/tensorflow/tensorflow)（通常通过其高级 API [Keras](https://github.com/keras-team/keras) 使用）、[Caffe 2](https://github.com/caffe2/caffe2) 和 [Apache MXNet](https://github.com/apache/incubator-mxnet) 所取代。第三代工具，即用于深度学习的必要工具，可以说是由 [Chainer](https://github.com/chainer/chainer) 带头的，它使用类似于 Python NumPy 的语法来描述模型。[PyTorch](https://github.com/pytorch/pytorch)、MXNet 的 [Gluon API](https://github.com/apache/incubator-mxnet) 和 [Jax](https://github.com/google/jax) 都采纳了这一想法。

系统研究人员构建更好的工具和构建更好的神经网络的统计建模者之间的分工大大简化了事情。例如，训练线性 Logistic 回归模型曾经是一个不平凡的家庭作业问题，值得在 2014 年向卡内基梅隆大学的新机器学习博士生提供。到目前为止，只需少于 10 行代码即可完成这项任务，将它牢牢地交给程序员掌握。

## 成功案例

人工智能在交付成果方面有悠久的历史，否则将难以实现。例如，自 1990 年代以来，使用光学字符识别的邮件分拣系统一直在部署。毕竟，这是著名的 MNIST 手写数字数据集的来源。同样适用于银行存款的阅读支票和申请人信誉评分。会自动检查财务交易是否存在欺诈。这构成了许多电子商务支付系统的支柱，例如 PayPal、Stripe、支付宝、微信、苹果、Visa 和万事达卡。几十年来，国际象棋的计算机程序一直是竞争力。机器学习提供互联网上的搜索、推荐、个性化和排名。换句话说，机器学习是普遍的，尽管往往隐藏在视线之外。

直到最近，人工智能才成为关注点，主要是由于解决以前被认为难以解决并与消费者直接相关的问题的解决方案。许多此类进展归功于深度学习。

* 苹果的 Siri、亚马逊的 Alexa 和谷歌的助手等智能助手能够以合理的准确度回答口头问题。这包括诸如打开灯光开关（对残疾人的福音），直到预约理发师和提供电话支持对话等简单的任务。这可能是人工智能正在影响我们生活的最明显迹象。
* 数字助手的一个关键要素是准确识别语音的能力。此类系统的准确性逐渐提高到某些应用程序中它们达到人类平等的程度 :cite:`Xiong.Wu.Alleva.ea.2018`。
* 对象识别同样走了很长的路。在 2010 年，估计图片中的物体是一项相当具有挑战性的任务。在 iMagenet 基准测试中，来自 NEC Labs 和伊利诺伊大学厄巴纳-香槟分校的研究人员实现了 28％ :cite:`Lin.Lv.Zhu.ea.2010` 的前 5 个错误率。到 2017 年，这个错误率已降至 2.25％ :cite:`Hu.Shen.Sun.2018`。同样，在识别鸟类或诊断皮肤癌方面也取得了惊人的成果。
* 游戏曾经是人类智能的堡垒。从 Td-Gammon 开始，一个使用时间差异强化学习、算法和计算进度玩步步高的程序已经导致了适用于各种应用的算法。与步步高不同，国际象棋的状态空间和一系列动作要复杂得多。DeepBlue 使用大规模的并行性、特殊用途硬件和通过游戏树 :cite:`Campbell.Hoane-Jr.Hsu.2002` 进行高效搜索击败了 Garry Kasparov。由于其巨大的州空间，Go 还是更加困难。Alphago 使用深度学习结合蒙特卡洛树采样 :cite:`Silver.Huang.Maddison.ea.2016`，于 2015 年达到了人类平等。扑克的挑战是州空间很大，没有完全观察（我们不知道对手的牌）。Libratus 使用高效的结构化策略 :cite:`Brown.Sandholm.2017` 超过了人类在扑克中的表现。这说明了游戏领域令人印象深刻的进步，以及高级算法在其中发挥了关键作用的事实。
* 人工智能进展的另一个迹象是自动驾驶汽车和卡车的出现。尽管完全自治尚未完全实现，但在这方面已经取得了良好的进展，特斯拉、NVIDIA 和 Waymo 等公司运输的产品至少可以实现部分自主权。使完全自主如此具有挑战性的是，正确的驾驶需要感知、推理和将规则纳入系统的能力。目前，深度学习主要用于这些问题的计算机视觉方面。其余部分都由工程师进行了大量调整。

同样，上面的列表几乎没有划痕机器学习影响实际应用的表面。例如，机器人技术、物流、计算生物学、粒子物理学和天文学等最近一些最令人印象深刻的进展，至少在部分方面是机器学习。因此，机器学习正成为工程师和科学家无处不在的工具。

人工智能启示录或人工智能奇点的问题经常在关于 AI 的非技术性文章中提出。人们担心的是，不知何故，机器学习系统将变得有感性，并独立于程序员（和主人）决定直接影响人类生计的事情。在某种程度上，人工智能已经立即影响人类的生计：信用度自动评估，自动驾驶员主要是驾驶车辆，关于是否准予保释的决定使用统计数据作为输入。更轻率的是，我们可以要求 Alexa 打开咖啡机。

幸运的是，我们远不是一个能够操纵人类创作者（或烧掉咖啡）的有情感的 AI 系统。首先，人工智能系统是以特定、面向目标的方式进行设计、培训和部署的。虽然他们的行为可能会给人一般智力的幻觉，但是这种设计的基础是规则、启发式和统计模型的组合。其次，目前 * 人工通用智能 * 的工具根本不存在能够改进自身、理性自我以及能够在尝试解决一般任务的同时修改、扩展和改进自己的架构的工具。

更紧迫的问题是人工智能在我们的日常生活中的使用情况。卡车司机和商店助理完成的许多艰巨任务很可能会而且将会自动化。农场机器人可能会降低有机农业的成本，但它们也将自动化收获操作。工业革命的这一阶段可能会对社会的广大阶层产生深远的影响，因为卡车司机和商店助理是许多国家最常见的工作。此外，如果不加谨慎地应用统计模型，可能会导致种族、性别或年龄偏见，并引起人们对程序公正性的合理担忧，如果自动化以推动相应的决策。重要的是要确保小心使用这些算法。根据我们今天所知道的情况，这让我们感到关切的问题比恶毒超级情报摧毁人类的潜力更为迫切。

## 特点

到目前为止，我们已经广泛谈论了机器学习，这既是人工智能的分支，也是人工智能的一种方法。尽管深度学习是机器学习的一个子集，但令人眼花缭乱的算法和应用程序使人难以评估深度学习的具体成分。这与尝试固定披萨所需成分一样困难，因为几乎每个组件都是可替代的。

正如我们所描述的那样，机器学习可以使用数据学习输入和输出之间的转换，例如将音频转换为语音识别中的文本。在这样做时，通常需要以适合算法的方式表示数据，以便将这些表示形式转换为输出。
*深度学习 * 确切地说是 * 深度 *
它的模型学习了许多 * 层 * 的变换，其中每个图层都提供一个级别的表示。例如，输入附近的图层可能表示数据的低级详细信息，而靠近分类输出的图层可能表示用于区分的更抽象的概念。由于 * 代表学习 * 旨在寻找表示本身，深度学习可以称为多层次表示学习。

到目前为止，我们讨论过的问题，例如从原始音频信号中学习、图像的原始像素值，或者在任意长度的句子与外语中的对应句子之间的映射，都是深度学习表现出色以及传统机器学习方法失败的地方。事实证明，这些多层模型能够以前的工具无法处理低级别的感知数据。可以说，深度学习方法中最重要的共同点是使用 * 端到端培训 *。也就是说，我们不是基于单独调整的组件来组装系统，而是构建系统，然后共同调整其性能。例如，在计算机视觉中，科学家曾经将 * 特征工程 * 的过程与构建机器学习模型的过程分开。Canny 边缘检测器 :cite:`Canny.1987` 和 Lowe 的 SIFT 功能提取器 :cite:`Lowe.2004` 作为将图像映射到特征矢量的算法，在过去十多年来一直占据最高水平。在过去的日子里，将机器学习应用于这些问题的关键部分在于提出手动设计的方法，将数据转换为适合浅层模型的某种形式。不幸的是，与算法自动执行的数百万个选择进行一致的评估相比，人类只能通过独创性实现的几乎没有什么。当深度学习接管时，这些功能提取器被自动调整的过滤器取代，从而获得了卓越的准确性。

因此，深度学习的一个关键优势是，深度学习不仅取代了传统学习管道末端的浅层模型，还取代了特征工程的劳动密集型过程。此外，通过取代大部分特定领域的预处理，深度学习消除了以前将计算机视觉、语音识别、自然语言处理、医学信息学和其他应用领域分开的许多界限，为应对多样化提供了一套统一的工具问题。

除了端到端培训之外，我们正在经历从参数化统计描述向完全非参数模型的过渡。当数据稀缺时，需要依靠简化对现实的假设才能获得有用的模型。当数据丰富时，可以用更准确地适应现实的非参数模型来取代。在某种程度上，这反映了物理学在上个世纪中叶随着计算机的可用性而取得的进展。人们现在可以诉诸关联的偏微分方程的数值模拟，而不是求解电子手工行为的参数近似值。这导致模型更加准确，尽管往往以牺牲可解释性为代价。

与之前工作的另一个区别是接受了次优解决方案，处理非凸非线性优化问题，以及在证明之前愿意尝试一些事情。这种在处理统计问题方面新发现的经验主义，加上人才的迅速涌入，导致了实用算法的迅速进展，尽管在许多情况下，以修改和重新发明已存在的工具为代价。

最后，深度学习社区以跨学术界限和企业界限共享工具而自豪，发布了许多优秀的图书馆、统计模型和训练有素的网络作为开源。正是本着这种精神，形成这本书的笔记本可以免费供发行和使用。我们一直在努力减少每个人学习深度学习的访问障碍，我们希望读者能从中受益。

## 摘要

* 机器学习研究计算机系统如何利用经验（通常是数据）来提高特定任务的性能。它结合了统计、数据挖掘和优化的想法。通常，它被用作实施 AI 解决方案的手段。
* 作为机器学习课程，代表性学习侧重于如何自动找到表示数据的适当方式。深度学习是通过学习多层次的转换来学习多层次的表示。
* 深度学习不仅取代了传统机器学习管道末端的浅模型，还取代了特征工程的劳动密集型过程。
* 近期深度学习的进展大部分是由廉价传感器和互联网规模应用产生的大量数据以及计算的重大进展（主要是通过 GPU）引发的。
* 整个系统优化是获得高性能的关键组成部分。高效的深度学习框架的可用性使这种框架的设计和实施变得更加容易。

## 练习

1. 您当前正在编写的代码的哪些部分可以 “学习”，即通过学习和自动确定代码中做出的设计选择来改进？你的代码是否包含启发式设计选择？
1. 你遇到的哪些问题有很多解决问题的例子，但没有具体的方法来自动化它们？这些可能是使用深度学习的首要候选人。
1. 将人工智能的发展视为新的工业革命，算法和数据之间的关系是什么？它与蒸汽机和煤炭类似吗？根本区别是什么？
1. 您还可以在哪里应用端到端培训方法，例如 :numref:`fig_ml_loop`，物理学、工程学和计量经济学？

[Discussions](https://discuss.d2l.ai/t/22)
