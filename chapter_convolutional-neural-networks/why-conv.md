# 从完全连接层到卷积
:label:`sec_why-conv`

迄今为止，在我们处理表格数据时，我们迄今讨论的模型仍然是适当的选择。通过表格，我们的意思是数据由与示例对应的行和与要素对应的列组成。对于表格数据，我们可能会预计我们所寻求的模式可能涉及要素之间的交互，但我们并不认为有关要素如何交互的任何结构 * 优先级 *。

有时候，我们确实缺乏指导精湛架构构建的知识。在这些情况下，MLP 可能是我们所能做的最好。然而，对于高维感知数据，这种无结构网络可能会变得难以操作。

例如，让我们回到我们的跑步例子来区分猫和狗。假设我们在数据收集方面做了一项彻底的工作，收集一百万像素照片的注释数据集。这意味着对网络的每个输入都有一百万个维度。即使大幅缩小到一千个隐藏尺寸，也需要一个以 $10^6 \times 10^3 = 10^9$ 参数为特征的完全连接层。除非我们拥有大量的 GPU、分布式优化的人才和非常耐心，否则学习这个网络的参数可能是不可行的。

仔细的读者可能会反对这一论点，理由是可能不需要一百万像素的分辨率。然而，虽然我们可以摆脱十万像素，但我们的大小为 1000 的隐藏图层严重低估了学习图像的良好表示所需的隐藏单元数量，所以一个实用的系统仍然需要数十亿个参数。此外，通过拟合如此多的参数来学习分类器可能需要收集大量的数据集。然而今天，人类和计算机都能够区分猫从狗相当好，看似矛盾这些直觉。这是因为图像表现出丰富的结构，可以被人类和机器学习模型所利用。卷积神经网络 (CNN) 是机器学习用于利用自然图像中某些已知结构的一种创造性方式。

## 不变性

想象一下，你想检测图像中的对象。似乎合理的是，无论我们用来识别对象的方法都不应过分关注图像中对象的精确位置。理想情况下，我们的系统应该利用这些知识。猪通常不飞，飞机通常不游泳。尽管如此，我们仍然应该认识到一只猪是一个出现在图像的顶部。我们可以从儿童游戏 “沃尔多在哪里”（如 :numref:`img_waldo`）中汲取灵感。游戏由一些混乱的场景与活动爆裂.Waldo 出现在每个地方，通常潜伏在某些不太可能的位置。读者的目标是找到他。尽管他特有的装备，这可能是令人惊讶的困难，由于大量的干扰。但是，* Waldo 看起来像 * 并不取决于 * Waldo 所在的位置 *。我们可以使用 Waldo 检测器扫描图像，该检测器可以为每个补丁分配一个分数，表明补丁包含 Waldo 的可能性。CNN 系统化了这个 * 空间不变性 * 的概念，利用它来学习具有较少参数的有用表示。

![An image of the "Where's Waldo" game.](../img/where-wally-walker-books.jpg)
:width:`400px`
:label:`img_waldo`

我们现在可以通过列举几个要求来指导我们设计适合计算机视觉的神经网络架构，使这些直觉更具体：

1. 在最早的图层中，我们的网络应该对同一修补程序作出类似的响应，无论它在图像中出现的位置如何。此原理称为 * 翻译不变 *。
1. 网络最早的图层应集中在局部区域，而不考虑远处区域的图像内容。这是 * 本地化 * 原则。最终，可以聚合这些局部表示，以便在整个图像级别进行预测。

让我们看看这是如何转化为数学。

## 约束 MLP

首先，我们可以考虑一个具有二维图像 $\mathbf{X}$ 的 MLP 作为输入和它们的直接隐藏表示 $\mathbf{H}$ 类似地表示为数学矩阵和代码中的二维张量，其中 $\mathbf{X}$ 和 $\mathbf{H}$ 都具有相同的形状。让那个下沉。我们现在认为，不仅输入，而且隐藏的表示形式具有空间结构。

让 $[\mathbf{X}]_{i, j}$ 和 $[\mathbf{H}]_{i, j}$ 分别表示输入图像和隐藏表示中位置的像素（$i$，$j$）。因此，为了让每个隐藏单位接收来自每个输入像素的输入，我们将从使用权重矩阵（正如我们以前在 MLP 中所做的那样）切换到将我们的参数表示为四阶权重张量 $\mathsf{W}$。假设 $\mathbf{U}$ 包含偏差，我们可以正式将完全连接的图层表示为

$$\begin{aligned} \left[\mathbf{H}\right]_{i, j} &= [\mathbf{U}]_{i, j} + \sum_k \sum_l[\mathsf{W}]_{i, j, k, l}  [\mathbf{X}]_{k, l}\\ &=  [\mathbf{U}]_{i, j} +
\sum_a \sum_b [\mathsf{V}]_{i, j, a, b}  [\mathbf{X}]_{i+a, j+b}.\end{aligned},$$

其中，从 $\mathsf{W}$ 到 $\mathsf{V}$ 的开关现在完全是表面的，因为在两个四阶张量的系数之间存在一对一的对应。我们简单地重新索引下标 $(k, l)$，这样就是 $k = i+a$ 和 $l = j+b$。换句话说，我们设置了 $[\mathsf{V}]_{i, j, a, b} = [\mathsf{W}]_{i, j, i+a, j+b}$。指数 $a$ 和 $b$ 运行在正和负偏移上，覆盖整个图像。对于隐藏表示 $[\mathbf{H}]_{i, j}$ 中的任何给定位置（$i$，$j$），我们通过将 $x$ 中的像素求和计算其值，以 $(i, j)$ 为中心，并以 $[\mathsf{V}]_{i, j, a, b}$ 为中心。

### 翻译不变性

现在让我们援引上面确立的第一个原则：翻译不变性。这意味着输入 $\mathbf{X}$ 中的偏移应该简单地导致隐藏表示 $\mathbf{H}$ 中的偏移。这是可能的，只有当 $\mathsf{V}$ 和 $\mathbf{U}$ 实际上并不依赖于 $(i, j)$，也就是说，我们有 $[\mathsf{V}]_{i, j, a, b} = [\mathbf{V}]_{a, b}$ 和 $\mathbf{U}$ 是一个常数，比如说 $u$。因此，我们可以简化 $\mathbf{H}$ 的定义：

$$[\mathbf{H}]_{i, j} = u + \sum_a\sum_b [\mathbf{V}]_{a, b}  [\mathbf{X}]_{i+a, j+b}.$$

这是一个 * 卷积 *！我们正在对位置 $(i, j)$ 附近的像素进行有效的加权，并且系数为 $[\mathbf{V}]_{a, b}$，以获得值 $[\mathbf{H}]_{i, j}$。请注意，$[\mathbf{V}]_{a, b}$ 所需的系数比 $[\mathsf{V}]_{i, j, a, b}$ 少得多，因为它不再依赖于图像中的位置。我们取得了重大进展！

###  地方性

现在让我们援引第二项原则：地方性。如上所述，我们认为，为了收集相关信息来评估 $[\mathbf{H}]_{i, j}$ 正在发生的情况，我们不应该看太远的位置 $(i, j)$。这意味着，在某些范围之外，我们应该设置 $[\mathbf{V}]_{a, b} = 0$。相当地，我们可以将 $[\mathbf{H}]_{i, j}$ 重写为

$$[\mathbf{H}]_{i, j} = u + \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} [\mathbf{V}]_{a, b}  [\mathbf{X}]_{i+a, j+b}.$$
:eqlabel:`eq_conv-layer`

请注意，简而言之，:eqref:`eq_conv-layer` 是一个卷积层 *。
*卷积神经网络 * (CNN)
是一个包含卷积层的特殊神经网络系列。在深度学习研究社区中，$\mathbf{V}$ 被称为 * 卷积内核 *、* 过滤器 *，或者只是图层的 * 权重 *，这些权重通常是可学习的参数。当局区域较小时，与完全连接的网络相比，差异可能很大。虽然以前，我们可能需要数十亿个参数来表示图像处理网络中的单个图层，但现在我们通常只需要几百个参数，而不会改变输入或隐藏表示的维度。这种大幅减少参数所付出的代价是，我们的功能现在是翻译不变的，并且我们的图层只能包含本地信息，在确定每个隐藏激活的价值时。所有学习都取决于施加感应偏差。当这种偏差与现实相符时，我们会得到有效采样的模型，能够很好地推广到看不见的数据。但是，当然，如果这些偏见与现实不一致，例如，如果图像证明不是翻译不变，我们的模型甚至可能难以适应我们的训练数据。

## 卷积

在进一步讨论之前，我们应该简要地回顾为什么上述操作被称为卷积。在数学中，两个函数之间的 * 卷积 *，例如 $f, g: \mathbb{R}^d \to \mathbb{R}$ 被定义为

$$(f * g)(\mathbf{x}) = \int f(\mathbf{z}) g(\mathbf{x}-\mathbf{z}) d\mathbf{z}.$$

也就是说，当一个函数被 “翻转” 并移动 $\mathbf{x}$ 时，我们测量 $f$ 和 $g$ 之间的重叠。每当我们有离散对象时，积分变成一个总和。例如，对于索引超过 $\mathbb{Z}$ 的平方可汇总无限维向量集中的向量，我们得到以下定义：

$$(f * g)(i) = \sum_a f(a) g(i-a).$$

对于二维张量，我们有一个相应的总和，分别为 $f$ 和 $(i-a, j-b)$ 的指数：

$$(f * g)(i, j) = \sum_a\sum_b f(a, b) g(i-a, j-b).$$
:eqlabel:`eq_2d-conv-discrete`

这看起来类似于 :eqref:`eq_conv-layer`，有一个主要区别。我们不是使用 $(i+a, j+b)$，而是使用差异。但请注意，这种区别主要是表面的，因为我们总是可以匹配 :eqref:`eq_conv-layer` 和 :eqref:`eq_2d-conv-discrete` 之间的符号。我们在 :eqref:`eq_conv-layer` 中的最初定义更正确地描述了 * 交叉关系 *。我们将在下一节中回到这个问题。

## 《沃尔多在哪里》重新审视

回到我们的 Waldo 探测器，让我们看看这是什么样子。卷积层选取给定尺寸的窗口，并根据滤波器 $\mathsf{V}$ 称重强度，如 :numref:`fig_waldo_mask` 所示。我们可能会学习一个模型，以便在 “虚拟度” 最高的地方，我们应该在隐藏图层表示中找到一个峰值。

![Detect Waldo.](../img/waldo-mask.jpg)
:width:`400px`
:label:`fig_waldo_mask`

### 频道
:label:`subsec_why-conv-channels`

这种方法只有一个问题。到目前为止，我们幸福地忽略了图像由三个通道组成：红色、绿色和蓝色。实际上，图像不是二维物体，而是三阶张量，其特点是高度、宽度和通道，例如，形状为 $1024 \times 1024 \times 3$ 像素。虽然这些轴中的前两个涉及空间关系，但第三个轴可被视为为每个像素位置分配多维表示。

因此，我们指数为 $\mathsf{X}$。卷积滤波器必须相应地适应。我们现在已经有了 $[\mathsf{V}]_{a,b,c}$，而不是我们现在有了 $[\mathsf{V}]_{a,b,c}$。

此外，就像我们的输入包含三阶张量一样，最好将我们的隐藏表示形式设计为三阶张量 $\mathsf{H}$ 也是一个好主意。换句话说，我们需要一个与每个空间位置相对应的隐藏表示的整个向量，而不是仅仅有一个与每个空间位置对应的隐藏表示。我们可以将隐藏的表示视为包含一些堆叠在彼此顶部的二维网格。与输入一样，这些有时称为 * 通道 *。它们有时也称为 * 要素地图 *，因为每个要素都向后续图层提供了一组已学习要素的空间化。直观地说，您可能会想象，在较靠近输入的较低图层中，某些通道可能会专门用于识别边缘，而其他通道则可以识别纹理。

为了在输入 ($\mathsf{X}$) 和隐藏表示 ($\mathsf{H}$) 中支持多个通道，我们可以在 $\mathsf{V}$ 中添加第四个坐标：$[\mathsf{V}]_{a, b, c, d}$。把一切都放在一起，我们有：

$$[\mathsf{H}]_{i,j,d} = \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} \sum_c [\mathsf{V}]_{a, b, c, d} [\mathsf{X}]_{i+a, j+b, c},$$
:eqlabel:`eq_conv-layer-channels`

其中 $d$ 用隐藏表示形式索引输出通道 $\mathsf{H}$。随后的卷积层将继续采用三阶张量 $\mathsf{H}$ 作为输入。更广泛地说，:eqref:`eq_conv-layer-channels` 是多个通道的卷积层的定义，其中 $\mathsf{V}$ 是图层的内核或滤波器。

我们仍然需要处理许多行动。例如，我们需要弄清楚如何将所有隐藏表示合并到单个输出中，例如，图像中是否有 Waldo * 任何位置 *。我们还需要决定如何高效地计算事物，如何组合多层，适当的激活函数，以及如何做出合理的设计选择来产生实际上有效的网络。我们在本章其余部分讨论这些问题。

## 摘要

* 图像中的翻译不变性意味着图像的所有补丁都将以相同的方式进行处理。
* 局部性意味着只使用一小部分像素邻域来计算相应的隐藏表示。
* 在图像处理中，卷积图层所需的参数通常比完全连接图层少得多。
* CNN 是一个包含卷积层的特殊神经网络系列。
* 输入和输出通道允许我们的模型在每个空间位置捕获图像的多个方面。

## 练习

1. 假设卷积内核的大小是 $\Delta = 0$。显示在这种情况下，卷积内核为每组通道独立实现一个 MLP。
1. 为什么翻译不变性毕竟不是一个好主意？
1. 在决定如何处理与图像边界上像素位置相对应的隐藏表示时，我们必须处理哪些问题？
1. 描述音频的类似卷积层。
1. 您认为卷积图层可能也适用于文本数据吗？为什么或为什么不？
1. 证明这一点。

[Discussions](https://discuss.d2l.ai/t/64)
