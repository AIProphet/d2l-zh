# 从完全连接的层到卷积
:label:`sec_why-conv`

处理表格数据时，我们之前讨论的MLP模型仍然适用。这里的表格数据，每行分别对应每个样本，每列对应每个特征，我们预计这些特征之间会交互，但我们并没有假设任何关于特征如何交互的结构。然而，对于高维感知数据，这种MLP单一结构的网络可能会变得笨拙。


例如，在之前区分猫和狗的例子中，假设我们收集了一个百万像素照片的注释数据集，这意味着神经网络的每个输入都有一百万个维度。即使是减少到一千个隐藏层，也需要一个以$10^6 \times 10^3 = 10^9$个参数为特征的完全连接层。除非我们有大量的gpu，一个分布式优化的天才以及超乎常人的耐心，否则很难学习这个网络的参数。


细心的读者可能会反对这一论点，认为可能不需要一百万像素的分辨率。
然而，即使我们减小为十万像素，1000隐藏单元的隐藏层可能不足以学习到良好的图像特征，所以我们仍然需要数十亿个参数。
此外，拟合不胜枚举的参数还需要收集大量的数据集，然而人类视觉和传统机器学习模型都能在小数据集上很好地区分猫和狗，这启发我们去深度挖掘图像中可以被人类和机器学习模型捕捉的丰富的二维结构。
而卷积神经网络（convolutional neural networks，CNN）就是利用二维结构处理图像，是一种创造性的神经网络。


## 空间不变性

想象一下，在一个对象检测任务中，识别对象的方法都不应过分在意图像中物体的确切位置。所以我们的识别对象系统应该利用这些知识，比如猪通常不在天上飞，飞机通常不会游泳。
我们可以从儿童游戏 ”沃尔多在哪里”（:numref:`img_waldo`）中汲取一些灵感。
这个游戏包括一些混乱的场景，而沃尔多通常潜伏在一些不太可能的位置，游戏玩家的目标是找到沃尔多。
尽管沃尔多的很有特点，在眼花缭乱的场景中找到他可能十分困难。

但是，沃尔多潜藏的地方并不取决于它出现在图像中的哪个位置。
由此我们可以使用一个“沃尔多检测器”扫描图像，该检测器将图像分成数个小贴片，并为每个贴片打分，表示这个贴片包含沃尔多的可能性。CNN系统化了这个“空间不变性”的概念，用较少参数来学习有用的特征。


![An image of the "Where's Waldo" game.](../img/where-wally-walker-books.jpg)
:width:`400px`
:label:`img_waldo`


现在，我们将之前的直觉具体化，来设计一下适用于计算机视觉的神经网络体系结构：

1. 平移不变性：在前部神经网络的层中，应该对相同的图像区域做出类似的响应，不管它出现在图像中的哪个位置。这个原理即为“平移不变性”。
1. 局部性：神经网络的早些层应该集中在图像中的局部区域，而不考虑遥远区域的图像内容，这就是“局部性”原则。最终，这些局部特征可以聚合起来，在整个图像级别上做出预测。

接下来我们看看如何将以上直觉转化为数学。



## 限制MLP

首先，假设以二维图像$\mathbf{X}$作为mlp的输入，其隐藏表示$\mathbf{H}$在数学上为矩阵，在代码中为二维张量，其中$\mathbf{X}$和$\mathbf{H}$具有相同的形状。由此，我们认为输入$\mathbf{X}$和隐藏表示$\mathbf{H}$都具有空间结构。

让$[\mathbf{X}]{i, j}$和$[\mathbf{H}]{i, j}$分别表示输入图像和隐藏表示中（$i$, $j$）处的像素。因此，为了让每个隐藏神经元接收每个输入像素，我们将参数从权重矩阵替换为四阶权重张量$\mathsf{W}$,如同我们先前在MLP中所做的那样。假设$\mathbf{U}$包含偏差参数，我们可以将全连通层表示为

$$\begin{aligned} \left[\mathbf{H}\right]{i, j} &= [\mathbf{U}]{i, j} + \sum_k \sum_l[\mathsf{W}]{i, j, k, l} [\mathbf{X}]{k, l}\ &= [\mathbf{U}]{i, j} + \sum_a \sum_b [\mathsf{V}]{i, j, a, b} [\mathbf{X}]_{i+a, j+b}.\end{aligned}$$

其中，从$\mathsf{W}$到$\mathsf{V}$的转换只是形式的转换，因为在两个四阶张量中，系数之间存在一对一的对应关系。
我们只需重新索引下标$(k, l)$，使$k = i+a$和$l = j+b$。换句话说，我们设置了$[\mathsf{V}]{i, j, a, b} = [\mathsf{W}]{i, j, i+a, j+b}$。索引$a$和$b$覆盖了正偏移和负偏移，覆盖了整个图像。对于隐藏表示$[\mathbf{H}]{i, j}$中的任何给定位置（$i$, $j$），我们通过对$x$中以$(i, j)$为中心并按$[\mathsf{V}]{i, j, a, b}$权重的像素求和来计算其值。


### 平移不变性

首先引用上面的第一个原则”翻译不变性“，这意味着输入$\mathbf{X}$中的移位应该只与隐藏表示$\mathbf{H}$中的移位有关。只有当$\mathsf{V}$和$\mathbf{U}$实际上不依赖于$(i, j)$时，这才有可能，也就是说，我们有$[\mathsf{V}]{i, j, a, b} = [\mathbf{V}]{a, b}$，$\mathbf{U}$是一个常数，比如$u$。因此，我们可以简化$\mathbf{H}$为：

$$[\mathbf{H}]{i, j} = u + \sum_a\sum_b [\mathbf{V}]{a, b} [\mathbf{X}]_{i+a, j+b}.$$

这就是卷积！我们使用系数$(i+a, j+b)$有效地加权位置$(i, j)$附近的像素以获得隐藏表示$[\mathbf{H}]{i, j}$。注意，$[\mathbf{V}]{a, b}$的参数比$[\mathsf{V}]_{i, j, a, b}$少很多，因为它不再依赖于图像中的位置。我们已经通过平移不变性取得了重大进展！


### 局部性

现在引用第二个原则“局部性”。如上所述，为了收集用来训练$[\mathbf{H}]{i, j}$参数的相关信息，我们不应关注离$(i, j)$很远的地方。这意味着在$|a|> \Delta$或$|b| > \Delta$的范围之外，我们可以假定$[\mathbf{V}]{a, b} = 0$。同理，我们可以将$[\mathbf{H}]_{i, j}$重写为

$$[\mathbf{H}]{i, j} = u + \sum{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} [\mathbf{V}]{a, b} [\mathbf{X}]{i+a, j+b}.$$ :eqlabel:eq_conv-layer

简而言之，:eqref:eq_conv-layer是一个卷积层，而卷积神经网络是包含卷积层的一类特殊神经网络。在深度学习研究社区中，$\mathbf{V}$被称为卷积核或者过滤器，是可学习的权重。当局部区域很小时，卷积神经网络与完全连接的网络的训练差异可能是巨大的。以前，我们可能需要数十亿个参数来表示图像处理网络中的一个层，而现在卷积层通常只需要几百个参数，而且不改变输入或隐藏表示的维数。以上所有的权重学习都依赖于归纳偏差，当这种偏差与实际情况相符时，我们就可以得到有效的样本模型，这些模型能很好地推广到不可见的数据中。但如果这些偏差与实际情况不符，比如当图像不是平移不变时，我们的模型可能难以学习训练数据。











###  地方地

现在让我们援引第二个原则：地域性。如上所述，我们认为，我们不应该远离 $(i, j)$ 地点，以便收集相关信息来评估 $[\mathbf{H}]_{i, j}$ 发生的情况。这意味着在某个范围之外，我们应该设置 $|a|> \Delta$ 或 $|b| > \Delta$。同样地，我们可以将 $[\mathbf{H}]_{i, j}$ 重写为

$$[\mathbf{H}]_{i, j} = u + \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} [\mathbf{V}]_{a, b}  [\mathbf{X}]_{i+a, j+b}.$$
:eqlabel:`eq_conv-layer`

请注意，简而言之，:eqref:`eq_conv-layer` 是一个 * 卷积层 *。
*卷积神经网络 * (CNN)
是一个包含卷积层的特殊神经网络家族。在深度学习研究社区中，$\mathbf{V}$ 被称为 * 卷积内核 *、* 过滤器 * 或仅称为图层的 * 权重 *，这些参数通常是可学习的参数。当局部区域较小时，与完全连接的网络相比，差异可能很大。虽然以前，我们可能需要数十亿个参数来表示图像处理网络中的单个图层，但我们现在通常只需要几百个参数，而不会改变输入或隐藏制图表达的维度。为参数大幅减少付出的代价是，我们的特征现在是翻译不变的，我们的图层只能包含本地信息，当确定每个隐藏激活的价值时。所有的学习都取决于强加感应偏见。当这种偏差与现实一致时，我们得到了可以很好地概括到看不见的数据的样本效率模型。但是，当然，如果这些偏见与现实不一致，例如，如果图像不是翻译不变的，那么我们的模型可能会很难拟合我们的训练数据。

## 卷积

在进一步研究之前，我们应该简要回顾为什么上述操作被称为卷积。在数学中，两个函数之间的 * 卷积 *，比如说 $f, g: \mathbb{R}^d \to \mathbb{R}$ 被定义为

$$(f * g)(\mathbf{x}) = \int f(\mathbf{z}) g(\mathbf{x}-\mathbf{z}) d\mathbf{z}.$$

也就是说，当一个函数被 “翻转” 并移动 $\mathbf{x}$ 时，我们测量 $f$ 和 $g$ 之间的重叠。每当我们有离散的对象时，积分就会变成一个总和。例如，对于索引运行超过 $\mathbb{Z}$ 的方形可和无限维向量集合中的向量，我们得到以下定义：

$$(f * g)(i) = \sum_a f(a) g(i-a).$$

对于二维张量，我们有一个相应的总和，分别为 $f$ 和 $(i-a, j-b)$ 的指数：

$$(f * g)(i, j) = \sum_a\sum_b f(a, b) g(i-a, j-b).$$
:eqlabel:`eq_2d-conv-discrete`

这看起来类似于 :eqref:`eq_conv-layer`，有一个主要区别。我们不是使用 $(i+a, j+b)$，而是使用差异。但请注意，这种区别主要是表面性的，因为我们总是可以匹配 :eqref:`eq_conv-layer` 和 :eqref:`eq_2d-conv-discrete` 之间的符号。我们在 :eqref:`eq_conv-layer` 中的原始定义更正确地描述了 * 交叉关联 *。我们将在下一节中再次讨论这一问题。

## “沃尔多在哪里” 回顾

回到我们的 Waldo 探测器，让我们看看这是什么样子。卷积层根据滤波器 $\mathsf{V}$ 选取给定大小的窗口，并对强度进行称重，如 :numref:`fig_waldo_mask` 所示。我们可能旨在学习一个模型，以便在 “华尔顿” 最高的位置，我们应该在隐藏图层表示中找到一个峰值。

![Detect Waldo.](../img/waldo-mask.jpg)
:width:`400px`
:label:`fig_waldo_mask`

### 渠道
:label:`subsec_why-conv-channels`

这种方法只有一个问题。到目前为止，我们幸福地忽略了图像由 3 个通道组成：红色、绿色和蓝色。实际上，图像不是二维物体，而是三阶张量，其特征是高度、宽度和通道，例如形状为 $1024 \times 1024 \times 3$ 像素。虽然前两个轴涉及空间关系，但第三个轴可视为为每个像素位置分配多维制图表达。因此，我们的指数为 $\mathsf{X}$。卷积滤波器必须相应地适应。我们现在已经拥有了 $[\mathsf{V}]_{a,b,c}$，而不是 $[\mathbf{V}]_{a,b}$。

此外，正如我们的输入由三阶张量组成一样，最好将我们的隐藏表示类似于三阶张量 $\mathsf{H}$。换句话说，我们不仅需要对应于每个空间位置的单个隐藏制图表达，而是需要一个与每个空间位置相对应的整个隐藏制图表达矢量。我们可以认为隐藏的表示是由一些堆叠在彼此之上的二维网格组成的。与输入一样，这些通道有时称为 * 频道 *。它们有时也称为 * 要素地图 *，因为每个图层都为后续图层提供了一组空间化的学习要素。直观而言，您可能会想象在较接近输入的较低图层中，某些通道可能会专门识别边缘，而其他通道则可以识别纹理。

为了在输入 ($\mathsf{X}$) 和隐藏表示 ($\mathsf{H}$) 中支持多个通道，我们可以将第四个坐标添加到 $\mathsf{V}$：$[\mathsf{V}]_{a, b, c, d}$。把我们所拥有的一切放在一起：

$$[\mathsf{H}]_{i,j,d} = \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} \sum_c [\mathsf{V}]_{a, b, c, d} [\mathsf{X}]_{i+a, j+b, c},$$
:eqlabel:`eq_conv-layer-channels`

其中 $d$ 在隐藏的表示中对输出通道进行索引。随后的卷积层将继续采用三阶张量 $\mathsf{H}$ 作为输入。更一般地说，:eqref:`eq_conv-layer-channels` 是多个通道的卷积层的定义，其中 $\mathsf{V}$ 是层的内核或滤波器。

我们仍然需要处理许多行动。例如，我们需要弄清楚如何将所有隐藏的表示组合到单个输出中，例如，图像中是否有 Waldo * 在任何位置。我们还需要决定如何高效地计算事物，如何组合多层、适当的激活函数，以及如何做出合理的设计选择，以便产生实际上有效的网络。我们将在本章其余部分讨论这些问题。

## 摘要

* 图像中的翻译不变性意味着将以相同的方式处理图像的所有补丁。
* 局部性意味着只使用一小部分像素邻域来计算相应的隐藏制图表达。
* 在图像处理中，卷积图层所需的参数通常比完全连接的图层少得多。
* CNN 是一个特殊的神经网络系列，其中包含卷积层。
* 输入和输出通道允许我们的模型在每个空间位置捕捉图像的多个方面。

## 练习

1. 假定卷积内核的大小为 $\Delta = 0$。表明在这种情况下，卷积内核为每组通道独立实现 MLP。
1. 为什么翻译不变性毕竟不是一个好主意？
1. 在决定如何处理与图像边界上像素位置相对应的隐藏表示时，我们必须处理哪些问题？
1. 描述音频的类似卷积层。
1. 您是否认为卷积图层也可能适用于文本数据？为什么还是为什么不呢？
1. 证明那是什么

[Discussions](https://discuss.d2l.ai/t/64)
